{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Introduction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Problem Description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data-driven approaches are now used in many fields from business to science. Since data storage and computational power has become cheap, machine learning has gained popularity. However, the majority of tools that can extract dependencies from data, are designed for prediction problem. In this notebook a problem of decision support simulation is considered and it is shown that even good predictive models can lead to wrong conclusions. This occurs under some conditions summarized by an umbrella term called endogeneity. In particular, accuracy of predictions does not guarantee causal relationships detection.\n",
    "\n",
    "Suppose that situation is as follows. There is a freshly-hired manager that can assign treatment to items in order to increase target metric. Treatment is binary, i.e. for each item it is assigned or it is absent. Because treatment costs something, its assignment should be optimized - only some items should be treated. A historical dataset of items performance is given, but the manager does not know that previously treatment was assigned predominantely based on values of just one parameter. Moreover, this parameter is not included in the dataset. To make the situation more weird, an extra assumption can be introduced - now it is impossible to measure values of the omitted parameter not only for old items, but also for a new ones too. By the way, manager wants to create a system that predicts an item's target metric in case of treatment and in case of absence of treatment. If this system is deployed, the manager can compare these two cases and decide whether effect of treatment worths its costs.\n",
    "\n",
    "If machine learning approach results in good prediction scores, chances are that the manager does not suspect that important variable is omitted (at least until some expenses are generated by wrong decisions). Hence, domain knowledge and data understanding are still required for modelling based on data. This is of particular importance when datasets contain values that are produced by someone's decisions, because there is no guarantee that future decisions will not change dramatically. On the flip side, if all factors that affect decisions are included into a dataset, i.e. there is selection on observables for treatment assignment, a powerful enough model is able to estimate treatment effect correctly.\n",
    "\n",
    "The described case may look too artificial, but here are two real-world examples of similar issues:\n",
    "\n",
    "* A neural network is trained to detect certain phrase in recorded speech. Unfortunately, all occurrences of the phrase in the learning sample are recorded by the same microphone in the same room and this flaw is not known. As a result, variable that indicates occurrence of the phrase and unobservable variable that indicates used microphone are confound. Network does not understand which target to learn and so produces good results during cross-validation and on hold-out test set, but poor results in a production environment.\n",
    "\n",
    "* In labour econometrics, a problem of estimation higher education effect on wages is well studied. A subtle issue here is that people with higher abilities have more willingness to earn degrees and also they have more chances to have bigger salaries. Abilities are unobservable variable and their effect is attributed mainly to higher education, because there is strong correlation between these variables. Hence, naive modelling leads to overestimation of higher education effect. \n",
    "\n",
    "Probably, sections of the notebook that illustrate ways to overcome lack of important unobservable variables, will be released after some time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To read more about causality in data analysis, it is possible to look at these papers:\n",
    "\n",
    "1. *Angrist J, Pischke J-S. Mostly Harmless Econometrics. Princeton University Press, 2009.*\n",
    "\n",
    "2. *Varian H. Big Data: New Tricks for Econometrics. Journal of Economic Perspectives, 28(2): 3â€“28, 2013*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Software Requirements"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This notebook does not use any packages beyond a list of those that are quite popular in scientific computing. Use `conda` or `pip` to install any of them."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Preparations"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### General"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from itertools import combinations\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split, KFold, GridSearchCV\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "# Startup settings can not suppress a warning from XGBRegressor and so this is needed.\n",
    "import warnings\n",
    "with warnings.catch_warnings():\n",
    "    warnings.simplefilter(\"ignore\")\n",
    "    from xgboost import XGBRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "np.random.seed(seed=361)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Synthetic Dataset Generation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us generate an unobservable parameter and an indicator of treatment such that they are highly correlated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "unobservable = np.hstack((np.ones(10000), np.zeros(10000)))\n",
    "treatment = np.hstack((np.ones(9000), np.zeros(10000), np.ones(1000)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1. ,  0.8],\n",
       "       [ 0.8,  1. ]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.corrcoef(unobservable, treatment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now create historical dataset that is used for learning predictive model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def synthesize_dataset(unobservable, treatment,\n",
    "                       given_exogenous=None, n_exogenous_to_draw=2,\n",
    "                       weights_matrix=np.array([[5, 0, 0, 0],\n",
    "                                                [0, 1, 1, 0],\n",
    "                                                [0, 1, 2, 1],\n",
    "                                                [0, 0, 1, 3]]).T):\n",
    "    \"\"\"\n",
    "    A helper function for repetitive\n",
    "    pieces of code.\n",
    "    \n",
    "    Creates a dataset, where target depends on\n",
    "    `unobservable`, but `unobservable` is not\n",
    "    included as a feature. Independent features\n",
    "    can be passed as `given_exogenous` as well as\n",
    "    drawn from Gaussian distribution.\n",
    "    \n",
    "    Target is generated as linear combination of\n",
    "    features and their interactions in the\n",
    "    following manner. Order features as below:\n",
    "    unobservable variable, treatment indicator,\n",
    "    given exogenous features, drawn exogenous\n",
    "    features. Then the (i, i)th element of\n",
    "    `weights_matrix` defines coefficient of\n",
    "    the i-th feature and the (i, j)th element\n",
    "    of `weights_matrix` (where i != j) defines\n",
    "    coefficient of interaction between the i-th\n",
    "    and j-th features.\n",
    "\n",
    "    @type unobservable: numpy.ndarray\n",
    "    @type treatment: numpy.ndarray\n",
    "    @type given_exogenous: numpy.ndarray\n",
    "    @type n_exogenous_to_draw: numpy.ndarray\n",
    "    @type weights_matrix: numpy.ndarray\n",
    "    @return: numpy.ndarray, numpy.ndarray\n",
    "    \"\"\"\n",
    "\n",
    "    try:\n",
    "        assert unobservable.shape == treatment.shape\n",
    "    except AssertionError:\n",
    "        raise ValueError(\"`unobservable` and `treatment` are not aligned.\")\n",
    "    try:\n",
    "        if given_exogenous is not None:\n",
    "            assert unobservable.shape[0] == given_exogenous.shape[0]\n",
    "    except AssertionError:\n",
    "        raise ValueError(\"`unobservable` and `given_exogenous` are not \" +\n",
    "                         \"aligned. Try to transpose `given_exogenous`.\")\n",
    "    try:\n",
    "        assert weights_matrix.shape[0] == weights_matrix.shape[1]\n",
    "    except AssertionError:\n",
    "        raise ValueError(\"Matrix of weights is not square.\")\n",
    "    try:\n",
    "        indices = list(range(weights_matrix.shape[0]))\n",
    "        for i, j in combinations(indices, 2):\n",
    "            assert weights_matrix[i, j] == weights_matrix[j, i]\n",
    "    except AssertionError:\n",
    "        raise ValueError(\"Matrix of weigths is not symmetric.\")\n",
    "    try:\n",
    "        len_of_given = given_exogenous.shape[1] \\\n",
    "                       if given_exogenous is not None \\\n",
    "                       else 0\n",
    "        assert 2 + len_of_given + n_exogenous_to_draw == weights_matrix.shape[0]\n",
    "    except AssertionError:\n",
    "        raise ValueError(\"Number of weights is not equal to that of features.\")\n",
    "\n",
    "    drawn_features = []\n",
    "    for i in range(n_exogenous_to_draw):\n",
    "        current_feature = np.random.normal(size=unobservable.shape[0])\n",
    "        drawn_features.append(current_feature)\n",
    "    if given_exogenous is None:\n",
    "        features = np.vstack([unobservable, treatment] + drawn_features).T\n",
    "    else:\n",
    "        features = np.vstack([unobservable, treatment, given_exogenous.T] +\n",
    "                             drawn_features).T\n",
    "    target = np.dot(features, weights_matrix.diagonal())\n",
    "    interactions = [weights_matrix[i, j] * features[:, i] * features[:, j]\n",
    "                    for i, j in combinations(indices, 2)]\n",
    "    target = np.sum(np.vstack([target] + interactions), axis=0)\n",
    "    return features[:, 1:], target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "learning_X, learning_y = synthesize_dataset(unobservable, treatment)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now create two datasets for simulation where the only difference between them is that in the first one treatment is absent and in the second one treatment is assigned to all items."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "unobservable = np.hstack((np.ones(2500), np.zeros(2500)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "no_treatment = np.zeros(5000)\n",
    "full_treatment = np.ones(5000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "no_treatment_X, no_treatment_y = synthesize_dataset(unobservable, no_treatment)\n",
    "full_treatment_X, full_treatment_y = synthesize_dataset(unobservable, full_treatment,\n",
    "                                                        no_treatment_X[:, 1:], 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Look at the data that are used for simulation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.        ,  1.58191727, -1.17154285],\n",
       "       [ 0.        , -0.56614096, -0.24566541],\n",
       "       [ 0.        , -0.3521775 ,  2.37789361],\n",
       "       [ 0.        , -1.19089718, -0.54156554],\n",
       "       [ 0.        ,  1.41070964, -0.14438024]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "no_treatment_X[:5, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.        ,  1.58191727, -1.17154285],\n",
       "       [ 1.        , -0.56614096, -0.24566541],\n",
       "       [ 1.        , -0.3521775 ,  2.37789361],\n",
       "       [ 1.        , -1.19089718, -0.54156554],\n",
       "       [ 1.        ,  1.41070964, -0.14438024]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_treatment_X[:5, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  2.79592213,   3.2698031 ,  10.59188519,   1.63845791,   7.18459995])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "no_treatment_y[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([  5.3778394 ,   3.70366215,  11.23970769,   1.44756073,   9.59530959])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "full_treatment_y[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Good Model..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((15000, 3), (5000, 3), (15000,), (5000,))"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(learning_X, learning_y,\n",
    "                                                    random_state=361)\n",
    "X_train.shape, X_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tune_inform(X_train, y_train, rgr, grid_params, kf, scoring):\n",
    "    \"\"\"\n",
    "    Another helper function.\n",
    "    \n",
    "    @type X_train: numpy.ndarray\n",
    "    @type y_train: numpy.ndarray\n",
    "    @type rgr: any sklearn regressor\n",
    "    @type grid_params: dict\n",
    "    @type kf: any sklearn folds\n",
    "    @type scoring: string\n",
    "    @return: sklearn regressor\n",
    "    \"\"\"\n",
    "    grid_search_cv = GridSearchCV(rgr, grid_params, cv=kf,\n",
    "                                  scoring=scoring)\n",
    "    grid_search_cv.fit(X_train, y_train)\n",
    "    print(\"Best CV mean score: {}\".format(grid_search_cv.best_score_))\n",
    "    means = grid_search_cv.cv_results_['mean_test_score']\n",
    "    stds = grid_search_cv.cv_results_['std_test_score']\n",
    "    print(\"Detailed results:\")\n",
    "    for mean, std, params in zip(means, stds,\n",
    "                                 grid_search_cv.cv_results_['params']):\n",
    "        print(\"%0.3f (+/-%0.03f) for %r\" % (mean, 2 * std, params))\n",
    "    return grid_search_cv.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rgr = LinearRegression()\n",
    "grid_params = {'fit_intercept': [True, False]}\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=361)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let us use coefficient of determination as a scorer rather than MSE. Actually, they are linearly dependent: $R^2 = 1 - \\frac{MSE}{\\mathrm{Var}(y)}$, but coefficient of determination is easier to interpret."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best CV mean score: 0.8597040594785548\n",
      "Detailed results:\n",
      "0.860 (+/-0.007) for {'fit_intercept': True}\n",
      "0.854 (+/-0.008) for {'fit_intercept': False}\n"
     ]
    }
   ],
   "source": [
    "rgr = tune_inform(X_train, y_train, rgr, grid_params, kf, 'r2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.86724859617745653"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_hat = rgr.predict(X_test)\n",
    "r2_score(y_test, y_hat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Although true relationship is non-linear, predictive power of linear regression is good. Coefficient of determination is close to 1 and it means that the model expalins almost all variance of the target around its mean."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rgr = XGBRegressor()\n",
    "grid_params = {'n_estimators': [50, 100, 200, 300],\n",
    "               'max_depth': [3, 5],\n",
    "               'subsample': [0.8, 1]}\n",
    "kf = KFold(n_splits=5, shuffle=True, random_state=361)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best CV mean score: 0.9052404587389057\n",
      "Detailed results:\n",
      "0.900 (+/-0.008) for {'max_depth': 3, 'subsample': 0.8, 'n_estimators': 50}\n",
      "0.900 (+/-0.008) for {'max_depth': 3, 'subsample': 1, 'n_estimators': 50}\n",
      "0.905 (+/-0.010) for {'max_depth': 3, 'subsample': 0.8, 'n_estimators': 100}\n",
      "0.905 (+/-0.010) for {'max_depth': 3, 'subsample': 1, 'n_estimators': 100}\n",
      "0.905 (+/-0.011) for {'max_depth': 3, 'subsample': 0.8, 'n_estimators': 200}\n",
      "0.905 (+/-0.011) for {'max_depth': 3, 'subsample': 1, 'n_estimators': 200}\n",
      "0.905 (+/-0.011) for {'max_depth': 3, 'subsample': 0.8, 'n_estimators': 300}\n",
      "0.905 (+/-0.011) for {'max_depth': 3, 'subsample': 1, 'n_estimators': 300}\n",
      "0.905 (+/-0.009) for {'max_depth': 5, 'subsample': 0.8, 'n_estimators': 50}\n",
      "0.904 (+/-0.010) for {'max_depth': 5, 'subsample': 1, 'n_estimators': 50}\n",
      "0.905 (+/-0.010) for {'max_depth': 5, 'subsample': 0.8, 'n_estimators': 100}\n",
      "0.904 (+/-0.010) for {'max_depth': 5, 'subsample': 1, 'n_estimators': 100}\n",
      "0.904 (+/-0.010) for {'max_depth': 5, 'subsample': 0.8, 'n_estimators': 200}\n",
      "0.904 (+/-0.010) for {'max_depth': 5, 'subsample': 1, 'n_estimators': 200}\n",
      "0.902 (+/-0.010) for {'max_depth': 5, 'subsample': 0.8, 'n_estimators': 300}\n",
      "0.902 (+/-0.010) for {'max_depth': 5, 'subsample': 1, 'n_estimators': 300}\n"
     ]
    }
   ],
   "source": [
    "rgr = tune_inform(X_train, y_train, rgr, grid_params, kf, 'r2')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It looks like almost all combinations of hyperparameters result in error that is close to irreducible error caused by mismatches between the indicator of treatment and the unobservable variable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.91312756427013864"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_hat = rgr.predict(X_test)\n",
    "r2_score(y_test, y_hat)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The score is close to 1 and it deceptively motivates to think that all important variables are included into the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# ...and Poor Simulation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# TODO: Prediction-vs-fact scatterplots."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.4.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
